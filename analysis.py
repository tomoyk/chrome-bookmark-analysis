import sqlite3
import json
import os
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from urllib.parse import urlparse, urlunparse

# âœ… Macç”¨ã®Chromeãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆProfile 1ï¼‰
CHROME_PROFILE = Path.home() / "Library" / "Application Support" / "Google" / "Chrome" / "Profile 1"

HISTORY_PATH = CHROME_PROFILE / "History"
BOOKMARKS_PATH = CHROME_PROFILE / "Bookmarks"

def chrome_time(dt):
    """datetime â†’ Chrome/Webkitã®ã‚¨ãƒãƒƒã‚¯æ™‚é–“ï¼ˆãƒã‚¤ã‚¯ãƒ­ç§’ï¼‰"""
    epoch_start = datetime(1601, 1, 1)
    delta = dt - epoch_start
    return int(delta.total_seconds() * 1_000_000)

def normalize_url(url):
    """ã‚¯ã‚¨ãƒªã¨ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆ?ã€œã€#ã€œï¼‰ã‚’é™¤ã„ãŸURLã«å¤‰æ›"""
    parsed = urlparse(url)
    normalized = urlunparse((parsed.scheme, parsed.netloc, parsed.path, '', '', ''))
    return normalized

def load_history(history_path):
    # 30æ—¥å‰ã®Webkitæ™‚é–“ã‚’è¨ˆç®— (History timestamps are stored in UTC)
    time_limit = chrome_time(datetime.utcnow() - timedelta(days=30))

    tmp_path = history_path.with_name("History_copy")
    tmp_path.write_bytes(history_path.read_bytes())

    conn = sqlite3.connect(tmp_path)
    query = f"""
    SELECT url, title, visit_count, last_visit_time
    FROM urls
    WHERE last_visit_time > {time_limit}
    ORDER BY visit_count DESC
    """
    df = pd.read_sql_query(query, conn)
    conn.close()
    tmp_path.unlink()

    # æ­£è¦åŒ–URLåˆ—ã‚’è¿½åŠ 
    df["normalized_url"] = df["url"].apply(normalize_url)
    return df

def load_bookmarks(bookmarks_path):
    with open(bookmarks_path, "r", encoding="utf-8") as f:
        bookmarks = json.load(f)
    urls = []

    def extract_urls(node):
        if isinstance(node, dict):
            if node.get("type") == "url":
                urls.append(node["url"])
            elif "children" in node:
                for child in node["children"]:
                    extract_urls(child)

    roots = bookmarks.get("roots", {})
    for root in roots.values():
        extract_urls(root)

    # æ­£è¦åŒ–ã—ã¦è¿”ã™
    return [normalize_url(url) for url in urls]

def main():
    print("ğŸ” Chromeã®å±¥æ­´ã¨ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    history_df = load_history(HISTORY_PATH)
    bookmarks = load_bookmarks(BOOKMARKS_PATH)

    # è¨ªå•å±¥æ­´ã®URLã¨å›æ•°ã‚’é›†è¨ˆï¼ˆæ­£è¦åŒ–URLå˜ä½ï¼‰
    visited_df = (
        history_df.groupby("normalized_url", as_index=False)["visit_count"]
        .sum()
        .sort_values(by="visit_count", ascending=False)
    )
    visited_urls = set(visited_df["normalized_url"])
    bookmarked_urls = set(bookmarks)

    # ğŸ“Œ ã‚¢ã‚¯ã‚»ã‚¹ãŒãªã„ or 5å›æœªæº€ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯
    low_access_bookmarks = []
    for url in bookmarks:
        if url not in visited_urls:
            low_access_bookmarks.append((url, 0))
        else:
            visit_count = visited_df.loc[visited_df["normalized_url"] == url, "visit_count"].values[0]
            if visit_count < 5:
                low_access_bookmarks.append((url, visit_count))

    # â­ ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ãŒé«˜ã„ãŒãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã•ã‚Œã¦ã„ãªã„URLï¼ˆä¸Šä½20ä»¶ï¼‰
    popular_unbookmarked = visited_df[~visited_df["normalized_url"].isin(bookmarked_urls)].head(20)

    print("\nğŸ“Œ éå»30æ—¥é–“ã§ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã¦ã„ãªã„ã€ã¾ãŸã¯5å›æœªæº€ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯:")
    for url, count in low_access_bookmarks:
        print(f" - {url} ï¼ˆ{count} å›è¨ªå•ï¼‰")

    print("\nâ­ ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ãŒé«˜ã„ãŒãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã•ã‚Œã¦ã„ãªã„URLï¼ˆéå»30æ—¥é–“ãƒ»ä¸Šä½20ä»¶ï¼‰:")
    for _, row in popular_unbookmarked.iterrows():
        print(f" - {row['normalized_url']} ï¼ˆ{row['visit_count']} å›è¨ªå•ï¼‰")

if __name__ == "__main__":
    main()

